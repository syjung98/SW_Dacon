{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import xgboost as xgb\n",
    "import psutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_score = []\n",
    "\n",
    "def objective(trial, data=train_X, target=train_Y):\n",
    "    \n",
    "    score = []\n",
    "    kf = StratifiedKFold(n_splits = 10, random_state = 42 , shuffle = True)\n",
    "\n",
    "    for train_fold, test_fold in tqdm(kf.split(train_X, train_Y), desc = 'k_fold'):\n",
    "        X_train, X_test, y_train, y_test = train_X.iloc[train_fold], train_X.iloc[test_fold], train_Y[train_fold], train_Y[test_fold] \n",
    "        params = {\n",
    "            \"objective\": \"multi:softprob\",\n",
    "            \"eval_metric\":'mlogloss', # ['auc', 'error']\n",
    "            \"booster\": 'gbtree', \n",
    "            #'tree_method':'gpu_hist', 'predictor':'gpu_predictor', 'gpu_id': 0, # use this line for gpu usage.\n",
    "            \"tree_method\": 'exact', 'gpu_id': -1,  # CPU 사용시 \n",
    "            \"verbosity\": 0,\n",
    "            'num_class':3,\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10), \n",
    "            \"learning_rate\": trial.suggest_uniform('learning_rate', 0.0001, 0.99),\n",
    "            'n_estimators': trial.suggest_int(\"n_estimators\", 1000, 10000, step=100), \n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0), \n",
    "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "            \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.5, 1.0),\n",
    "            \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-2, 1),\n",
    "            \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-2, 1),\n",
    "            'subsample': trial.suggest_discrete_uniform('subsample', 0.6, 1.0, 0.05),      \n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 2, 15),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1.0, log=True),\n",
    "            # 'num_parallel_tree': trial.suggest_int(\"num_parallel_tree\", 1, 500)\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBClassifier(**params)  \n",
    "        \n",
    "        model.fit(X_train,y_train,eval_set=[(X_test,y_test)],verbose=False)\n",
    "        \n",
    "        preds = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        score.append(auc_score)\n",
    "        real_score.append(auc_score)\n",
    "\n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "'''\n",
    "0.8558211379019417 and parameters: {'max_depth': 10, 'learning_rate': 0.11423799062437275, 'n_estimators': 6900, 'colsample_bytree': 0.7390924842332742, 'colsample_bylevel': 0.6940109759294105, 'colsample_bynode': 0.5496585400738032, 'reg_lambda': 0.9713492867033704, 'reg_alpha': 0.8147232205798981, 'subsample': 0.85, 'min_child_weight': 5, 'gamma': 0.16280391709890213}\n",
    "0.8765662376664448 and parameters: {'max_depth': 10, 'learning_rate': 0.025929426661789656, 'n_estimators': 6600, 'colsample_bytree': 0.7155456762839627, 'colsample_bylevel': 0.6123744502366096, 'colsample_bynode': 0.8016499020606728, 'reg_lambda': 0.0935399629775155, 'reg_alpha': 0.018771877229402035, 'subsample': 0.8, 'min_child_weight': 4, 'gamma': 0.6677845409584143}\n",
    "'''\n",
    "\n",
    "sampler = TPESampler(seed = 42)\n",
    "\n",
    "optim = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "optim.optimize(objective, n_trials=20) \n",
    "print(\"Best auc:\", optim.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for more XGBoost parameter informations, check this site : https://xgboost.readthedocs.io/en/stable/parameter.html   \n",
    "##### best performance archive.\n",
    "\n",
    "##### 0.8558211379019417 and parameters: {'max_depth': 10, 'learning_rate': 0.11423799062437275, 'n_estimators': 6900, 'colsample_bytree': 0.7390924842332742, 'colsample_bylevel': 0.6940109759294105, 'colsample_bynode': 0.5496585400738032, 'reg_lambda': 0.9713492867033704, 'reg_alpha': 0.8147232205798981, 'subsample': 0.85, 'min_child_weight': 5, 'gamma': 0.16280391709890213}\n",
    "##### 0.8765662376664448 and parameters: {'max_depth': 10, 'learning_rate': 0.025929426661789656, 'n_estimators': 6600, 'colsample_bytree': 0.7155456762839627, 'colsample_bylevel': 0.6123744502366096, 'colsample_bynode': 0.8016499020606728, 'reg_lambda': 0.0935399629775155, 'reg_alpha': 0.018771877229402035, 'subsample': 0.8, 'min_child_weight': 4, 'gamma': 0.6677845409584143}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
